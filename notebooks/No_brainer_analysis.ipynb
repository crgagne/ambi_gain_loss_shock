{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vp_list = ['06','07','10', '12', '13', '15', '16', '17', '18', '19', '20', '22'] #'23_2', '25_2', '26_2', '27_2', '28_2', '29', '30']\n",
    "resultnames = ['bic','aic','pseudoR2','pred_acc']\n",
    "model_param_df = np.array(['','','',3.0])\n",
    "model_summary_df = nobrainer_gainloss\n",
    "\n",
    "for vp in vp_list:\n",
    "    \n",
    "    df = gainloss_df[gainloss_df.MID == 'vp' + vp]\n",
    "    MID = 'vp' + vp\n",
    "        \n",
    "    for split in ['ambig_gain','ambig_loss','unambig_gain','unambig_loss']:\n",
    "        #print(split)\n",
    "        if 'unambig' in split:\n",
    "            paramnum='0'\n",
    "        else:\n",
    "            paramnum='1'\n",
    "        # Fit a model to the ambiguous gain trials \n",
    "        out = fit_model_split_amb_unamb_gain_loss(df, whichreturn= split, params=param_sets_split[paramnum],zscore=False)\n",
    "        \n",
    "    \n",
    "        modelname = out['modelname']\n",
    "\n",
    "        for result in resultnames:\n",
    "            model_summary_df.loc[(model_summary_df.MID== 'vp' + vp),result+'_'+split]=out[result]\n",
    "\n",
    "        params = out['params']\n",
    "        for param in params.index:\n",
    "            paramn = param.replace('_loss','')\n",
    "            paramn = paramn.replace('_gain','')\n",
    "            paramn = paramn.replace('_amb','')\n",
    "            paramn = paramn.replace('_rl','')\n",
    "            row = np.array([MID,paramn,split,params[param]])\n",
    "            model_param_df=np.vstack((model_param_df,row))\n",
    "\n",
    "model_param_df = pd.DataFrame(model_param_df,columns=['MID','parameter','split','beta'])\n",
    "model_param_df.drop(0,inplace=True) #df.index[0]\n",
    "model_param_df['beta']=model_param_df['beta'].astype('float')\n",
    "\n",
    "print(out['aic'])\n",
    "print(out['pred_acc'])\n",
    "print(out['modelname'])\n",
    "out['results'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../functions/\")\n",
    "import imp\n",
    "#for data preprocessing\n",
    "import Scripts_Data_Processing\n",
    "imp.reload(Scripts_Data_Processing)\n",
    "from Scripts_Data_Processing import *\n",
    "#for NoBrainer Analysis\n",
    "import NoBrainer_Analysis_AllinOne\n",
    "imp.reload( NoBrainer_Analysis_AllinOne)\n",
    "from  NoBrainer_Analysis_AllinOne import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gain/Loss No Brainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../functions/NoBrainer_Analysis_AllinOne.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['left_better']=left_better\n",
      "../functions/NoBrainer_Analysis_AllinOne.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['right_better']=right_better\n",
      "../functions/NoBrainer_Analysis_AllinOne.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['choseBetter'] = (df['resp'] == 'left') & (df['left_better']== True) | (df['resp'] == 'right') & (df['right_better']==True)\n",
      "../functions/NoBrainer_Analysis_AllinOne.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['noBrainer'] = (df['right_better'] != df['left_better'])\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "vp_perform_gainloss_list = []\n",
    "vp_nb_gainloss_list = []\n",
    "vp_list = ['06', '07', '10', '12', '13', '15', '16', '17', '18', '19', '20', '22', '23_2', '25_2', '26_2', '27_2', '28_2', '29', '30']\n",
    "for vp in vp_list:\n",
    "    path = os.path.join(os.getcwd(),'..','data','data_gainloss_logfiles','vp' + vp + '_gainloss_processed.csv')\n",
    "    df = pd.read_csv(path, sep=\",\")\n",
    "    #preprocess gainloss data\n",
    "    df=preprocess_gainloss(df)\n",
    "    #preprocess data\n",
    "    df = preprocess(df)\n",
    "    #store prepocessed data in list that contains data for all subjects (for later analysis)\n",
    "    df_list.append(df)\n",
    "    #create subset with unambiguous trials for no brainer analysis\n",
    "    nb_df = drop_ambi_trials(df)\n",
    "    #create variables indicating whether left or right was the better option\n",
    "    better_choice_gainloss(nb_df)\n",
    "    #indicate whether the better box was chosen\n",
    "    nb_df = right_choice(nb_df)\n",
    "    #only keep trials that are 'no brainers'\n",
    "    nb_df = keep_nobrainers(nb_df)\n",
    "    #calculate performance\n",
    "    vp_perform_gainloss = ['vp' + vp, vp_perf(nb_df)]\n",
    "    #store each vp performance in list\n",
    "    vp_perform_gainloss_list.append(vp_perform_gainloss)\n",
    "    #vp performance sectionwise\n",
    "    vp_nb_gainloss = nb_df.groupby('section').mean().add_prefix('gainloss_')[['gainloss_choseBetter']]\n",
    "    vp_nb_gainloss['MID'] = 'vp'+ vp\n",
    "    vp_nb_gainloss_list.append(vp_nb_gainloss)\n",
    "    \n",
    "#Merge dataframe list to single dataframe. \"inner\": Just take columns which exist in all dataframes    \n",
    "gainloss_df = pd.concat(df_list, ignore_index = True, join = 'inner')  \n",
    "#vp_gainloss_perf = pd.concat(vp_performance_list, ignore_index = True, join = 'inner')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shock No Brainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a7280511482d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msec\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msection_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'..'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'data_shock_logfiles'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Expt1Pain_Behaviour_vp'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvp\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msec\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mdf_dummy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskiprows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdf_dummy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'MID'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'vp'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mvp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "vp_list = ['06', '07', '10', '12', '13', '15', '16', '17', '18', '19', '20', '22', '23', '25', '26', '27', '28', '29', '30']\n",
    "vp_perform_shock_list = []\n",
    "vp_nb_shock_list = []\n",
    "section_list = ['1', '2', '3']\n",
    "for vp in vp_list:\n",
    "    df = []\n",
    "    for sec in section_list:\n",
    "        path = os.path.join(os.getcwd(),'..','data','data_shock_logfiles','Expt1Pain_Behaviour_vp' + vp + '_' + sec + '.txt')\n",
    "        df_dummy = pd.read_csv(path, sep=\"\\t\", skiprows = [0])\n",
    "        df_dummy['MID'] = 'vp'+ vp\n",
    "        df_dummy['section'] = sec\n",
    "        df_dummy.columns = df_dummy.columns.str.replace(' ','')\n",
    "        df.append(df_dummy)\n",
    "    #create a df that contains data from all sections    \n",
    "    df = pd.concat(df, ignore_index = True, join = 'inner')\n",
    "    #preprocess shock data\n",
    "    df = preprocess_shock(df)\n",
    "    #preprocess data\n",
    "    df = preprocess(df)\n",
    "    #store prepocessed data in list that contains data for all subjects (for later analysis)\n",
    "    df_list.append(df)\n",
    "    #create subset with unambiguous trials for no brainer analysis\n",
    "    nb_df = drop_ambi_trials(df)\n",
    "    #create variables indicating whether left or right was the better option\n",
    "    nb_df = better_choice_shock(nb_df)\n",
    "    #indicate whether the better box was chosen\n",
    "    nb_df = right_choice(nb_df)\n",
    "    #only keep trials that are 'no brainers'\n",
    "    nb_df = keep_nobrainers(nb_df)\n",
    "    #calculate performance\n",
    "    vp_perform_shock = ['vp' + vp, vp_perf(nb_df)]\n",
    "    #store each vp performance in list\n",
    "    vp_perform_shock_list.append(vp_perform_shock)\n",
    "    #vp performance sectionwise\n",
    "    vp_nb_shock = nb_df.groupby('section').mean().add_prefix('shock_')[['shock_choseBetter']]\n",
    "    vp_nb_shock['MID'] = 'vp'+ vp\n",
    "    vp_nb_shock_list.append(vp_nb_shock)\n",
    "\n",
    "#create complete df for shock condition with all vps        \n",
    "shock_df = pd.concat(df_list, ignore_index = True, join = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nb_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4fb56a9b45db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnb_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nb_df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display results per VP and Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[         gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                    0.833333  vp06\n",
       " 2                    1.000000  vp06\n",
       " 3                    0.960000  vp06,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                    1.000000  vp07\n",
       " 2                    0.666667  vp07\n",
       " 3                    1.000000  vp07,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                         1.0  vp10\n",
       " 2                         1.0  vp10\n",
       " 3                         1.0  vp10,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                        1.00  vp12\n",
       " 2                        1.00  vp12\n",
       " 3                        0.92  vp12,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                        1.00  vp13\n",
       " 2                        1.00  vp13\n",
       " 3                        0.88  vp13,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                        1.00  vp15\n",
       " 2                        1.00  vp15\n",
       " 3                        0.92  vp15,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                        1.00  vp16\n",
       " 2                        1.00  vp16\n",
       " 3                        0.96  vp16,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                    0.833333  vp17\n",
       " 2                    1.000000  vp17\n",
       " 3                    1.000000  vp17,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                    0.833333  vp18\n",
       " 2                    1.000000  vp18\n",
       " 3                    0.960000  vp18,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                        1.00  vp19\n",
       " 2                        1.00  vp19\n",
       " 3                        0.52  vp19,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                    0.833333  vp20\n",
       " 2                    1.000000  vp20\n",
       " 3                    1.000000  vp20,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                    1.000000  vp22\n",
       " 2                    0.666667  vp22\n",
       " 3                    0.880000  vp22,          gainloss_choseBetter     MID\n",
       " section                              \n",
       " 1                    0.818182  vp23_2\n",
       " 2                    1.000000  vp23_2\n",
       " 3                    1.000000  vp23_2,          gainloss_choseBetter     MID\n",
       " section                              \n",
       " 1                         1.0  vp25_2\n",
       " 2                         1.0  vp25_2\n",
       " 3                         1.0  vp25_2,          gainloss_choseBetter     MID\n",
       " section                              \n",
       " 1                    1.000000  vp26_2\n",
       " 2                    1.000000  vp26_2\n",
       " 3                    0.972222  vp26_2,          gainloss_choseBetter     MID\n",
       " section                              \n",
       " 1                         1.0  vp27_2\n",
       " 2                         1.0  vp27_2\n",
       " 3                         1.0  vp27_2,          gainloss_choseBetter     MID\n",
       " section                              \n",
       " 1                    0.833333  vp28_2\n",
       " 2                    0.666667  vp28_2\n",
       " 3                    0.888889  vp28_2,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                    0.833333  vp29\n",
       " 2                    0.333333  vp29\n",
       " 3                    0.520000  vp29,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                    0.833333  vp30\n",
       " 2                    1.000000  vp30\n",
       " 3                    0.805556  vp30]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vp_nb_gainloss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[         shock_choseBetter   MID\n",
       " section                         \n",
       " 1                 1.000000  vp06\n",
       " 2                 0.625000  vp06\n",
       " 3                 0.428571  vp06,          shock_choseBetter   MID\n",
       " section                         \n",
       " 1                 1.000000  vp07\n",
       " 2                 0.562500  vp07\n",
       " 3                 0.428571  vp07,          shock_choseBetter   MID\n",
       " section                         \n",
       " 1                 1.000000  vp10\n",
       " 2                 0.625000  vp10\n",
       " 3                 0.857143  vp10,          shock_choseBetter   MID\n",
       " section                         \n",
       " 1                      0.8  vp12\n",
       " 2                      0.5  vp12\n",
       " 3                      0.5  vp12,          shock_choseBetter   MID\n",
       " section                         \n",
       " 1                 1.000000  vp13\n",
       " 2                 0.500000  vp13\n",
       " 3                 0.428571  vp13,          shock_choseBetter   MID\n",
       " section                         \n",
       " 1                 1.000000  vp15\n",
       " 2                 0.500000  vp15\n",
       " 3                 0.357143  vp15,          shock_choseBetter   MID\n",
       " section                         \n",
       " 1                      1.0  vp16\n",
       " 2                      0.5  vp16\n",
       " 3                      0.5  vp16,          shock_choseBetter   MID\n",
       " section                         \n",
       " 1                 1.000000  vp17\n",
       " 2                 0.562500  vp17\n",
       " 3                 0.642857  vp17,          shock_choseBetter   MID\n",
       " section                         \n",
       " 1                 1.000000  vp18\n",
       " 2                 0.937500  vp18\n",
       " 3                 0.785714  vp18,          shock_choseBetter   MID\n",
       " section                         \n",
       " 1                 1.000000  vp19\n",
       " 2                 0.500000  vp19\n",
       " 3                 0.357143  vp19,          shock_choseBetter   MID\n",
       " section                         \n",
       " 1                 0.800000  vp20\n",
       " 2                 0.625000  vp20\n",
       " 3                 0.571429  vp20,          shock_choseBetter   MID\n",
       " section                         \n",
       " 1                 1.000000  vp22\n",
       " 2                 0.562500  vp22\n",
       " 3                 0.285714  vp22,          shock_choseBetter   MID\n",
       " section                         \n",
       " 1                 1.000000  vp23\n",
       " 2                 0.437500  vp23\n",
       " 3                 0.428571  vp23,          shock_choseBetter   MID\n",
       " section                         \n",
       " 1                 1.000000  vp25\n",
       " 2                 0.687500  vp25\n",
       " 3                 0.857143  vp25,          shock_choseBetter   MID\n",
       " section                         \n",
       " 1                 1.000000  vp26\n",
       " 2                 0.562500  vp26\n",
       " 3                 0.428571  vp26,          shock_choseBetter   MID\n",
       " section                         \n",
       " 1                    1.000  vp27\n",
       " 2                    0.625  vp27\n",
       " 3                    0.500  vp27,          shock_choseBetter   MID\n",
       " section                         \n",
       " 1                    0.800  vp28\n",
       " 2                    0.625  vp28\n",
       " 3                    0.500  vp28,          shock_choseBetter   MID\n",
       " section                         \n",
       " 1                     1.00  vp29\n",
       " 2                     0.75  vp29\n",
       " 3                     1.00  vp29,          shock_choseBetter   MID\n",
       " section                         \n",
       " 1                 1.000000  vp30\n",
       " 2                 0.687500  vp30\n",
       " 3                 0.857143  vp30]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vp_nb_shock_list"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
