{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Save Data Table \n",
    "\n",
    "- we'll want to put all this as a function instead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import glob\n",
    "import pickle\n",
    "import scipy\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../functions/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data processing functions # \n",
    "import Scripts_Data_Processing\n",
    "reload(Scripts_Data_Processing)\n",
    "from Scripts_Data_Processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import calculate_questionnaire_scores\n",
    "reload(calculate_questionnaire_scores)\n",
    "from calculate_questionnaire_scores import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../questionnaires/hit_batch_2017_4_17_ambiASIR_A12HZGOZQD5YK7.csv',\n",
       " '../../questionnaires/hit_batch_2017_4_17_ambiASIR_A12K9210P1R1DN.csv',\n",
       " '../../questionnaires/hit_batch_2017_4_17_ambiASIR_A14ADQ7RUN6TDY.csv',\n",
       " '../../questionnaires/hit_batch_2017_4_17_ambiASIR_A14TOBAPF6MMB5.csv',\n",
       " '../../questionnaires/hit_batch_2017_4_17_ambiASIR_A18BORMKPR29F2.csv',\n",
       " '../../questionnaires/hit_batch_2017_4_17_ambiASIR_A18RE2B07K9M88.csv',\n",
       " '../../questionnaires/hit_batch_2017_4_17_ambiASIR_A18TWORM22TW9U.csv',\n",
       " '../../questionnaires/hit_batch_2017_4_17_ambiASIR_A1BSA7FVVJGZ15.csv',\n",
       " '../../questionnaires/hit_batch_2017_4_17_ambiASIR_A1BWR5RBQDZQ16.csv']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = ['../../questionnaires/'+f for f in os.listdir('../../questionnaires/')] \n",
    "files.remove('../../questionnaires/.DS_Store')\n",
    "files[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- only using the combined data (other subjects are in a different questionnaires folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the table with Questionnaires Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def start_data_table_with_questionnaires(files):\n",
    "    data_participants = pd.DataFrame(columns=['MID','AID','date'])\n",
    "    from datetime import datetime\n",
    "\n",
    "    for ff,f in enumerate(files): \n",
    "            q = pd.read_csv(f)\n",
    "\n",
    "            if not q.empty:\n",
    "                AID = q.AID[0]\n",
    "                MID = q.MID[0]\n",
    "                date=str(get_date_from_filename(f))\n",
    "                if type(MID) is not str:\n",
    "                    MID=str(MID)\n",
    "                if type(AID) is not str:\n",
    "                    AID=str(AID)\n",
    "\n",
    "                # if MID and date are not already in the dataframe append\n",
    "                if data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),].empty:\n",
    "                    row = pd.DataFrame([(MID,AID,date)],columns=['MID','AID','date'])\n",
    "                    data_participants=data_participants.append(row)\n",
    "\n",
    "\n",
    "                # fix q to just have mathcing date entries\n",
    "                q['date'] = q['start_date'].apply(lambda x: str(x.split(' ')[0])) # change the date in q to be just day, month year\n",
    "                lastdate = q['date'].as_matrix()[-1]\n",
    "                q = q.loc[q['date']==lastdate] # take just end of the file, some subjects have earlier dates\n",
    "\n",
    "                date_in_f = datetime.strptime(date,'%Y-%m-%d')\n",
    "                try:\n",
    "                    date_in_q = datetime.strptime(q['date'].as_matrix()[0],'%m/%d/%y')\n",
    "                except:\n",
    "                    date_in_q = datetime.strptime(q['date'].as_matrix()[0],'%Y-%m-%d')\n",
    "\n",
    "\n",
    "                if (date_in_f.month==date_in_q.month) and (np.abs(date_in_f.day-date_in_q.day)<10): # make sure the dates in q are within 10 days of the filename\n",
    "\n",
    "\n",
    "                    # drop duplicate questions\n",
    "                    length_before = len(q)\n",
    "                    q = q.drop_duplicates(subset=['question'],keep='last')\n",
    "                    length_after=len(q)\n",
    "                    if length_before!=length_after:\n",
    "                        had_to_drop=1\n",
    "                    else:\n",
    "                        had_to_drop=0\n",
    "\n",
    "                    unique_responses = len(q.answer.value_counts())\n",
    "\n",
    "                    if 'STAI_Trait' in f:\n",
    "\n",
    "                        (STAI_Trait,STAI_Trait_anx,STAI_Trait_dep)=calc_stais(q)\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'STAI_Trait']=STAI_Trait\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'STAI_Trait_anx']=STAI_Trait_anx\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'STAI_Trait_dep']=STAI_Trait_dep\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'STAI_Trait_had_to_drop_rows']=had_to_drop\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'STAI_Trait_unique_responses']=unique_responses\n",
    "\n",
    "                    if 'STAI_State' in f:\n",
    "                        (STAI_State)=calc_stais_state(q)\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'STAI_State']=STAI_State\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'STAI_State_had_to_drop_rows']=had_to_drop\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'STAI_State_unique_responses']=unique_responses\n",
    "\n",
    "                    if 'BDI' in f:\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'BDI']=calc_bdi(q)\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'BDI_had_to_drop_rows']=had_to_drop\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'BDI_unique_responses']=unique_responses\n",
    "\n",
    "                    if 'MASQ' in f:\n",
    "\n",
    "                        (masq_mix_symp,masq_aa,masq_ad,masq_anx_symp,masq_dep_symp)=calc_MASQ(q)\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'MASQ.AA']=masq_aa\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'MASQ.AD']=masq_ad\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'MASQ.MS']=masq_mix_symp\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'MASQ.DS']=masq_dep_symp\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'MASQ.AS']=masq_anx_symp\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'MASQ_had_to_drop_rows']=had_to_drop\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'MASQ_unique_responses']=unique_responses\n",
    "\n",
    "                    if 'EPQ' in f:\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'EPQ']=calc_EPQ(q)\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'EPQ_had_to_drop_rows']=had_to_drop\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'EPQ_unique_responses']=unique_responses\n",
    "\n",
    "                    if 'PSWQ' in f:\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'PSWQ']=calc_PSWQ(q)\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'PSWQ_had_to_drop_rows']=had_to_drop\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'PSWQ_unique_responses']=unique_responses\n",
    "\n",
    "                    if 'CESD' in f:\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'CESD']=calc_CESD(q)\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'CESD_had_to_drop_rows']=had_to_drop\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'CESD_unique_responses']=unique_responses\n",
    "                    if 'ASIR' in f:\n",
    "                        (asir,asir16)=calc_ASIR(q)\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'ASIR']=asir\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'ASIR_had_to_drop_rows']=had_to_drop\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'ASIR_unique_responses']=unique_responses\n",
    "\n",
    "                    if 'IUS' in f:\n",
    "                        (IUS,IUS1,IUS2)=calc_IUS(q)\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'IUS']=IUS\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'IUS1']=IUS1\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'IUS2']=IUS2\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'IUS_had_to_drop_rows']=had_to_drop\n",
    "                        data_participants.loc[(data_participants.MID==MID) & (data_participants.date==date),'IUS_unique_responses']=unique_responses\n",
    "                else:\n",
    "                    print('bad: '+f)\n",
    "    return(data_participants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad: ../../questionnaires/hit_batch_2017_6_14_ambiMASQ_A1PUHCEBSOWETV.csv\n"
     ]
    }
   ],
   "source": [
    "data_participants = start_data_table_with_questionnaires(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AID</th>\n",
       "      <th>ASIR</th>\n",
       "      <th>ASIR_had_to_drop_rows</th>\n",
       "      <th>ASIR_unique_responses</th>\n",
       "      <th>BDI</th>\n",
       "      <th>BDI_had_to_drop_rows</th>\n",
       "      <th>BDI_unique_responses</th>\n",
       "      <th>CESD</th>\n",
       "      <th>CESD_had_to_drop_rows</th>\n",
       "      <th>CESD_unique_responses</th>\n",
       "      <th>...</th>\n",
       "      <th>PSWQ_unique_responses</th>\n",
       "      <th>STAI_State</th>\n",
       "      <th>STAI_State_had_to_drop_rows</th>\n",
       "      <th>STAI_State_unique_responses</th>\n",
       "      <th>STAI_Trait</th>\n",
       "      <th>STAI_Trait_anx</th>\n",
       "      <th>STAI_Trait_dep</th>\n",
       "      <th>STAI_Trait_had_to_drop_rows</th>\n",
       "      <th>STAI_Trait_unique_responses</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33LK57MYLUA9QA3R3JQA60A1P97ZST</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3QRYMNZ7FZMGOL2NPVK6LIZEHEGNTS</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>15</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34YB12FSQZT61YVHTU6Z9KVPMT9MGR</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3DUZQ9U6SNTSHQYH2M17LUX51XBVSX</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30LB5CDZNDF9P1JFUH7QWU4IUHT0ZC</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3H0W84IWBL7ZE0CIS7CSVG4NF1NREZ</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3PH3VY7DJM22XRK0NO0B3PDMVMGWZI</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35LDD5557B9B3KR0JLRE7CNITBZKM3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3P59JYT76MPKZZDU3CMMTUWFUUI2TH</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3Z9WI9EOZ0TPB6QPSOB1F7FMCPGHK7</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-04-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              AID  ASIR  ASIR_had_to_drop_rows  \\\n",
       "0  33LK57MYLUA9QA3R3JQA60A1P97ZST    28                      0   \n",
       "0  3QRYMNZ7FZMGOL2NPVK6LIZEHEGNTS    58                      0   \n",
       "0  34YB12FSQZT61YVHTU6Z9KVPMT9MGR    25                      0   \n",
       "0  3DUZQ9U6SNTSHQYH2M17LUX51XBVSX    10                      0   \n",
       "0  30LB5CDZNDF9P1JFUH7QWU4IUHT0ZC    30                      0   \n",
       "0  3H0W84IWBL7ZE0CIS7CSVG4NF1NREZ    92                      0   \n",
       "0  3PH3VY7DJM22XRK0NO0B3PDMVMGWZI   101                      0   \n",
       "0  35LDD5557B9B3KR0JLRE7CNITBZKM3   NaN                      0   \n",
       "0  3P59JYT76MPKZZDU3CMMTUWFUUI2TH    30                      0   \n",
       "0  3Z9WI9EOZ0TPB6QPSOB1F7FMCPGHK7    22                      0   \n",
       "\n",
       "   ASIR_unique_responses  BDI  BDI_had_to_drop_rows  BDI_unique_responses  \\\n",
       "0                      5    1                     0                     2   \n",
       "0                      5   11                     0                     3   \n",
       "0                      4    7                     0                     3   \n",
       "0                      3    3                     0                     2   \n",
       "0                      4   15                     0                     2   \n",
       "0                      5   14                     0                     4   \n",
       "0                      5   22                     0                     4   \n",
       "0                      5   37                     0                     4   \n",
       "0                      3    2                     0                     2   \n",
       "0                      4    1                     0                     2   \n",
       "\n",
       "   CESD  CESD_had_to_drop_rows  CESD_unique_responses     ...      \\\n",
       "0     5                      0                      4     ...       \n",
       "0    19                      0                      3     ...       \n",
       "0     4                      0                      4     ...       \n",
       "0     6                      0                      4     ...       \n",
       "0    22                      0                      4     ...       \n",
       "0    12                      0                      4     ...       \n",
       "0    20                      0                      3     ...       \n",
       "0    45                      0                      3     ...       \n",
       "0     8                      0                      3     ...       \n",
       "0     9                      0                      2     ...       \n",
       "\n",
       "   PSWQ_unique_responses  STAI_State  STAI_State_had_to_drop_rows  \\\n",
       "0                      4          37                            0   \n",
       "0                      5          41                            0   \n",
       "0                      4          28                            0   \n",
       "0                      4          34                            0   \n",
       "0                      4          46                            0   \n",
       "0                      5          36                            0   \n",
       "0                      4          26                            0   \n",
       "0                      4          61                            0   \n",
       "0                      3          32                            0   \n",
       "0                      4          32                            0   \n",
       "\n",
       "   STAI_State_unique_responses  STAI_Trait  STAI_Trait_anx  STAI_Trait_dep  \\\n",
       "0                            3          42              20              22   \n",
       "0                            3          49              15              34   \n",
       "0                            4          28              10              18   \n",
       "0                            4          37               9              28   \n",
       "0                            3          42              11              31   \n",
       "0                            3          38              16              22   \n",
       "0                            4          51              18              33   \n",
       "0                            4          56              18              38   \n",
       "0                            3          38              12              26   \n",
       "0                            4          42              10              32   \n",
       "\n",
       "   STAI_Trait_had_to_drop_rows  STAI_Trait_unique_responses        date  \n",
       "0                            0                            4  2017-04-17  \n",
       "0                            0                            3  2017-04-17  \n",
       "0                            0                            4  2017-04-17  \n",
       "0                            0                            3  2017-04-17  \n",
       "0                            0                            4  2017-04-17  \n",
       "0                            0                            4  2017-04-17  \n",
       "0                            0                            2  2017-04-17  \n",
       "0                            0                            4  2017-04-17  \n",
       "0                            0                            3  2017-04-17  \n",
       "0                            1                            3  2017-04-17  \n",
       "\n",
       "[10 rows x 38 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_participants.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Came Back Twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "removeindex = []\n",
    "for MID in data_participants.MID.unique():\n",
    "    indices = list(data_participants.loc[data_participants.MID==MID,].index)\n",
    "    #print(len(indices))\n",
    "    if indices>1: \n",
    "        removeindex = removeindex + indices[1::]\n",
    "\n",
    "data_participants.loc[removeindex,'CameBackTwice']=1\n",
    "data_participants.to_csv('../results/sub_table.csv',index=None)\n",
    "print(sum(data_participants['CameBackTwice']==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AID</th>\n",
       "      <th>ASIR</th>\n",
       "      <th>ASIR_had_to_drop_rows</th>\n",
       "      <th>ASIR_unique_responses</th>\n",
       "      <th>BDI</th>\n",
       "      <th>BDI_had_to_drop_rows</th>\n",
       "      <th>BDI_unique_responses</th>\n",
       "      <th>CESD</th>\n",
       "      <th>CESD_had_to_drop_rows</th>\n",
       "      <th>CESD_unique_responses</th>\n",
       "      <th>...</th>\n",
       "      <th>STAI_State</th>\n",
       "      <th>STAI_State_had_to_drop_rows</th>\n",
       "      <th>STAI_State_unique_responses</th>\n",
       "      <th>STAI_Trait</th>\n",
       "      <th>STAI_Trait_anx</th>\n",
       "      <th>STAI_Trait_dep</th>\n",
       "      <th>STAI_Trait_had_to_drop_rows</th>\n",
       "      <th>STAI_Trait_unique_responses</th>\n",
       "      <th>date</th>\n",
       "      <th>CameBackTwice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33LK57MYLUA9QA3R3JQA60A1P97ZST</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3QRYMNZ7FZMGOL2NPVK6LIZEHEGNTS</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>15</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34YB12FSQZT61YVHTU6Z9KVPMT9MGR</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3DUZQ9U6SNTSHQYH2M17LUX51XBVSX</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30LB5CDZNDF9P1JFUH7QWU4IUHT0ZC</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              AID  ASIR  ASIR_had_to_drop_rows  \\\n",
       "0  33LK57MYLUA9QA3R3JQA60A1P97ZST    28                      0   \n",
       "0  3QRYMNZ7FZMGOL2NPVK6LIZEHEGNTS    58                      0   \n",
       "0  34YB12FSQZT61YVHTU6Z9KVPMT9MGR    25                      0   \n",
       "0  3DUZQ9U6SNTSHQYH2M17LUX51XBVSX    10                      0   \n",
       "0  30LB5CDZNDF9P1JFUH7QWU4IUHT0ZC    30                      0   \n",
       "\n",
       "   ASIR_unique_responses  BDI  BDI_had_to_drop_rows  BDI_unique_responses  \\\n",
       "0                      5    1                     0                     2   \n",
       "0                      5   11                     0                     3   \n",
       "0                      4    7                     0                     3   \n",
       "0                      3    3                     0                     2   \n",
       "0                      4   15                     0                     2   \n",
       "\n",
       "   CESD  CESD_had_to_drop_rows  CESD_unique_responses      ...        \\\n",
       "0     5                      0                      4      ...         \n",
       "0    19                      0                      3      ...         \n",
       "0     4                      0                      4      ...         \n",
       "0     6                      0                      4      ...         \n",
       "0    22                      0                      4      ...         \n",
       "\n",
       "   STAI_State  STAI_State_had_to_drop_rows  STAI_State_unique_responses  \\\n",
       "0          37                            0                            3   \n",
       "0          41                            0                            3   \n",
       "0          28                            0                            4   \n",
       "0          34                            0                            4   \n",
       "0          46                            0                            3   \n",
       "\n",
       "   STAI_Trait  STAI_Trait_anx  STAI_Trait_dep  STAI_Trait_had_to_drop_rows  \\\n",
       "0          42              20              22                            0   \n",
       "0          49              15              34                            0   \n",
       "0          28              10              18                            0   \n",
       "0          37               9              28                            0   \n",
       "0          42              11              31                            0   \n",
       "\n",
       "   STAI_Trait_unique_responses        date  CameBackTwice  \n",
       "0                            4  2017-04-17            NaN  \n",
       "0                            3  2017-04-17            NaN  \n",
       "0                            4  2017-04-17            NaN  \n",
       "0                            3  2017-04-17            NaN  \n",
       "0                            4  2017-04-17            NaN  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_participants.to_csv('../results/sub_table_questionnaires_scores.csv',index=None)\n",
    "data_participants.to_csv('../results/sub_table.csv',index=None)\n",
    "print(len(data_participants))\n",
    "data_participants.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Number of Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_participants = pd.read_csv('../results/sub_table.csv')\n",
    "for index, row in data_participants.iterrows():\n",
    "    MID = row.MID\n",
    "    \n",
    "    datestr = row.date\n",
    "    datestr = datestr.replace('-','_')\n",
    "    datestr = datestr.replace('09','9')\n",
    "    datestr = datestr.replace('06','6')\n",
    "    datestr = datestr.replace('03','3') ### THIS IS SUPER IMPORTANT\n",
    "    datestr = datestr.replace('04','4')\n",
    "    \n",
    "    for task in ['loss','gain','combined']:\n",
    "        if task is not 'combined':\n",
    "            search  = '../results/trial_tables/*'+datestr+'*'+task+'*'+row.MID+'*'\n",
    "        else:\n",
    "            search  = '../../tasklogs/combined/*'+datestr+'*'+task+'*'+row.MID+'*'\n",
    "        files = glob.glob(search)\n",
    "        if len(files)>0:\n",
    "            sub = pd.read_csv(files[0]) # load subject data\n",
    "            \n",
    "            if task is not 'combined':\n",
    "                ntrials = np.sum(~np.isnan(sub.mag_u))\n",
    "                ntrials_responded = np.sum(~np.isnan(sub.choice))\n",
    "                mean_rt = np.nanmean(sub.rt)\n",
    "                number_no_resp = np.sum(sub.noresp)\n",
    "                startingpts = np.nan\n",
    "                totalpts= np.nan\n",
    "\n",
    "            else:\n",
    "                ntrials = np.sum(~np.isnan(sub.mag_left))\n",
    "                ntrials_responded = np.sum(sub.resp!='999')\n",
    "                mean_rt = np.nanmean(sub.reaction_time)\n",
    "                number_no_resp = ntrials-ntrials_responded \n",
    "                startingpts = sub.totalpoints.as_matrix()[0]\n",
    "                totalpts= sub.totalpoints.as_matrix()[-1]\n",
    "            \n",
    "            data_participants.loc[(data_participants['MID']==row.MID) \n",
    "                                  & (data_participants['date']==row.date),\n",
    "                                  'ntrials_'+task]=ntrials\n",
    "            data_participants.loc[(data_participants['MID']==row.MID) \n",
    "                                  & (data_participants['date']==row.date),\n",
    "                                  'ntrials_resp_'+task]=ntrials_responded\n",
    "            data_participants.loc[(data_participants['MID']==row.MID) \n",
    "                                  & (data_participants['date']==row.date),\n",
    "                                  'mean_RT_'+task]=mean_rt   \n",
    "            data_participants.loc[(data_participants['MID']==row.MID) \n",
    "                                  & (data_participants['date']==row.date),\n",
    "                                  'num_no_resp_'+task]=number_no_resp\n",
    "            data_participants.loc[(data_participants['MID']==row.MID) \n",
    "                                  & (data_participants['date']==row.date),\n",
    "                                  'totalpts'+task]=totalpts\n",
    "            data_participants.loc[(data_participants['MID']==row.MID) \n",
    "                                  & (data_participants['date']==row.date),\n",
    "                                  'startingpts'+task]=startingpts\n",
    "        else:\n",
    "            #print(row.MID)\n",
    "            data_participants.loc[(data_participants['MID']==row.MID) \n",
    "                                  & (data_participants['date']==row.date),\n",
    "                                  'ntrials_'+task]=np.nan\n",
    "            data_participants.loc[(data_participants['MID']==row.MID) \n",
    "                                  & (data_participants['date']==row.date),\n",
    "                                  'ntrials_resp_'+task]=np.nan\n",
    "            data_participants.loc[(data_participants['MID']==row.MID) \n",
    "                                  & (data_participants['date']==row.date),\n",
    "                                  'mean_RT_'+task]=np.nan\n",
    "\n",
    "            data_participants.loc[(data_participants['MID']==row.MID) \n",
    "                                  & (data_participants['date']==row.date),\n",
    "                                  'num_no_resp_'+task]=np.nan  \n",
    "            data_participants.loc[(data_participants['MID']==row.MID) \n",
    "                                  & (data_participants['date']==row.date),\n",
    "                                  'totalpts'+task]=np.nan\n",
    "            data_participants.loc[(data_participants['MID']==row.MID) \n",
    "                                  & (data_participants['date']==row.date),\n",
    "                                  'startingpts'+task]=np.nan\n",
    "            \n",
    "            \n",
    "data_participants.to_csv('../results/sub_table.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_participants = pd.read_csv('../results/sub_table.csv')\n",
    "files = glob.glob('../../batchlogs/*')\n",
    "f = files[1]\n",
    "participant_table = pd.read_csv(f) # get table\n",
    "for f in files:\n",
    "    participant_table = pd.read_csv(f) # get table\n",
    "    if 'RPP' in f: # check if its an RPP table\n",
    "        RPP = 1\n",
    "    else:\n",
    "        RPP = 0 \n",
    "    \n",
    "    date = str(get_date_from_filename(f))\n",
    "    \n",
    "    for MID in participant_table.MID.unique():\n",
    "        MID = str(MID)\n",
    "        data_participants.loc[(data_participants['MID']==MID) \n",
    "                                  & (data_participants['date']==date),\n",
    "                              'RPP']=RPP\n",
    "        data_participants.loc[(data_participants['MID']==MID) \n",
    "                                  & (data_participants['date']==date),\n",
    "                              'tasks']=participant_table.loc[participant_table.MID.astype('str')==MID,'tasks'].as_matrix()[0]\n",
    "        data_participants.loc[(data_participants['MID']==MID) \n",
    "                                  & (data_participants['date']==date),\n",
    "                              'progress_times']=participant_table.loc[participant_table.MID.astype('str')==MID,'progress_times'].as_matrix()[0]\n",
    "        \n",
    "        data_participants.loc[(data_participants['MID']==MID) \n",
    "                                  & (data_participants['date']==date),\n",
    "                              'AID']=participant_table.loc[participant_table.MID.astype('str')==MID,'AID'].as_matrix()[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        # for those with 2 tasks # does not save by date... does this cause a problem?/\n",
    "        if participant_table.loc[participant_table.MID.astype('str')==MID,'tasks'].as_matrix()[0].find('gain')<participant_table.loc[participant_table.MID.astype('str')==MID,'tasks'].as_matrix()[0].find('loss'):\n",
    "            data_participants.loc[data_participants.MID==MID,'task_order']='gain_first'\n",
    "        elif participant_table.loc[participant_table.MID.astype('str')==MID,'tasks'].as_matrix()[0].find('gain')>participant_table.loc[participant_table.MID.astype('str')==MID,'tasks'].as_matrix()[0].find('loss'):\n",
    "            data_participants.loc[data_participants.MID==MID,'task_order']='loss_first'\n",
    "        \n",
    "        tasks = participant_table.loc[participant_table.MID.astype('str')==MID,'tasks'].as_matrix()[0]\n",
    "        if tasks.find('loss')>0 and tasks.find('gain')<0:\n",
    "            data_participants.loc[data_participants.MID==MID,'task_order']='loss_first'\n",
    "\n",
    "        if tasks.find('loss')<0 and tasks.find('gain')>0:\n",
    "            data_participants.loc[data_participants.MID==MID,'task_order']='gain_first'\n",
    "\n",
    "data_participants.to_csv('../results/sub_table.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data_participants.AID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Brainer Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_participants = pd.read_csv('../results/sub_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "### THIS IS UPDATED 3/1/17 - to use. \n",
    "    \n",
    "def calc_no_brainer_per2(MID,date):\n",
    "    ''' Trys to get a ambi for an MID on a particular date. \n",
    "        If they have gain and loss tasks, itll give no brainers for each. \n",
    "        If they have combined. Itll give no brainers for gain loss within that'''\n",
    "    date = date.replace('-','_')\n",
    "    date = date.replace('09','9')\n",
    "    date = date.replace('06','6')\n",
    "    date = date.replace('03','3') ### THIS IS SUPER IMPORTANT\n",
    "    date = date.replace('04','4')\n",
    "    \n",
    "    try:\n",
    "        ##### LOSS TASK ####### \n",
    "        # get loss data \n",
    "        files = glob.glob('../../tasklogs/loss/hit*'+date+'*'+MID+'*')\n",
    "        sub =  get_trial_table(files[0])\n",
    "        \n",
    "        # first choose just non-ambiguous trials # \n",
    "        sub = sub.loc[(sub['ambig_l']==0) & (sub['ambig_r']==0),]\n",
    "        sub['mag_left']=sub['mag_left']*-1.0\n",
    "        sub['mag_right']=sub['mag_right']*-1.0\n",
    "        left_better = (sub['prob_o_l']<sub['prob_o_r']) & (sub['mag_left']>sub['mag_right'])\n",
    "        right_better = (sub['prob_o_r']<sub['prob_o_l']) & (sub['mag_right']>sub['mag_left'])\n",
    "        cor1=(sub.loc[left_better,'resp_r_1']==0).sum() # correctly chose 1\n",
    "        cor0=(sub.loc[right_better,'resp_r_1']==1).sum() # correctly chose 0 \n",
    "        n1 = len((sub.loc[left_better,]))\n",
    "        n0 = len((sub.loc[right_better,]))\n",
    "        nl=np.float(n1+n0)\n",
    "        if n1>0:\n",
    "            perc_correctl = np.float(cor1+cor0)/nl\n",
    "        else:\n",
    "            perc_correctl=0.0\n",
    "    except:\n",
    "        perc_correctl=np.nan\n",
    "        nl=np.nan\n",
    "    \n",
    "    ##### GAIN TASK #######\n",
    "    # get gain data \n",
    "    try:\n",
    "        # get gain data \n",
    "        files = glob.glob('../../tasklogs/gain/hit*'+date+'*'+MID+'*')\n",
    "        sub =  get_trial_table(files[0])\n",
    "\n",
    "        # first choose just non-ambiguous trials # \n",
    "        sub = sub.loc[(sub['ambig_l']==0) & (sub['ambig_r']==0),]\n",
    "        left_better = (sub['prob_o_l']>sub['prob_o_r']) & (sub['mag_left']>sub['mag_right'])\n",
    "        right_better = (sub['prob_o_r']>sub['prob_o_l']) & (sub['mag_right']>sub['mag_left'])\n",
    "        cor1=(sub.loc[left_better,'resp_r_1']==0).sum() # correctly chose 1\n",
    "        cor0=(sub.loc[right_better,'resp_r_1']==1).sum() # correctly chose 0 \n",
    "        n1 = len((sub.loc[left_better,]))\n",
    "        n0 = len((sub.loc[right_better,]))\n",
    "        ng=np.float(n1+n0)\n",
    "        if ng>0:\n",
    "            perc_correctg = np.float(cor1+cor0)/ng\n",
    "        else:\n",
    "            perc_correctg=0.0\n",
    "\n",
    "    except:\n",
    "        perc_correctg=np.nan\n",
    "        ng=np.nan\n",
    "        \n",
    "    ##### Combined Data #######\n",
    "    try: \n",
    "        files = glob.glob('../../tasklogs/combined/*'+date+'*'+MID+'*')\n",
    "        sub = get_trial_table(files[0],combined=True)\n",
    "\n",
    "        # first choose just non-ambiguous trials # \n",
    "        subnonamb = sub.loc[(sub['ambig_l']==0) & (sub['ambig_r']==0),]\n",
    "\n",
    "        # then choose gain  # \n",
    "        sub = subnonamb.loc[subnonamb['gain_or_loss_trial']=='gain']\n",
    "        left_better = (sub['prob_o_l']>sub['prob_o_r']) & (sub['mag_left']>sub['mag_right'])\n",
    "        right_better = (sub['prob_o_r']>sub['prob_o_l']) & (sub['mag_right']>sub['mag_left'])\n",
    "        cor1=(sub.loc[left_better,'resp_r_1']==0).sum() # correctly chose 1\n",
    "        cor0=(sub.loc[right_better,'resp_r_1']==1).sum() # correctly chose 0 \n",
    "        n1 = len((sub.loc[left_better,]))\n",
    "        n0 = len((sub.loc[right_better,]))\n",
    "        ng=np.float(n1+n0)\n",
    "        if ng>0:\n",
    "            perc_correctg = np.float(cor1+cor0)/ng\n",
    "        else:\n",
    "            perc_correctg=0.0\n",
    "        \n",
    "        # then choose loss \n",
    "        sub = subnonamb.loc[subnonamb['gain_or_loss_trial']=='loss']\n",
    "        left_better = (sub['prob_o_l']<sub['prob_o_r']) & (sub['mag_left']>sub['mag_right'])\n",
    "        right_better = (sub['prob_o_r']<sub['prob_o_l']) & (sub['mag_right']>sub['mag_left'])\n",
    "        cor1=(sub.loc[left_better,'resp_r_1']==0).sum() # correctly chose 1\n",
    "        cor0=(sub.loc[right_better,'resp_r_1']==1).sum() # correctly chose 0 \n",
    "        n1 = len((sub.loc[left_better,]))\n",
    "        n0 = len((sub.loc[right_better,]))\n",
    "        nl=np.float(n1+n0)\n",
    "        if n1>0:\n",
    "            perc_correctl = np.float(cor1+cor0)/nl\n",
    "        else:\n",
    "            perc_correctl=0.0\n",
    "            \n",
    "    except:\n",
    "        perc_correctg=np.nan\n",
    "        ng=np.nan\n",
    "        perc_correctl=np.nan\n",
    "        nl=np.nan\n",
    "    \n",
    "\n",
    "    return(perc_correctg,perc_correctl,ng,nl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index,row in data_participants.iterrows():\n",
    "    try:\n",
    "        (corg,corl,ng,nl) = calc_no_brainer_per2(row.MID,row.date)\n",
    "    except:\n",
    "       print('failed')\n",
    "       corg=np.nan\n",
    "       corl=np.nan\n",
    "       ng=np.nan\n",
    "       nl=np.nan\n",
    "    data_participants.loc[(data_participants['MID']==row.MID) \n",
    "                                  & (data_participants['date']==row.date),\n",
    "                           'no_brainer_per_cor_gain']=corg\n",
    "    data_participants.loc[(data_participants['MID']==row.MID) \n",
    "                                  & (data_participants['date']==row.date),\n",
    "                           'no_brainer_per_cor_loss']=corl\n",
    "    data_participants.loc[(data_participants['MID']==row.MID) \n",
    "                                  & (data_participants['date']==row.date),\n",
    "                           'no_brainer_n_gain']=ng\n",
    "    data_participants.loc[(data_participants['MID']==row.MID) \n",
    "                                  & (data_participants['date']==row.date),\n",
    "                           'no_brainer_n_loss']=nl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "data_participants.to_csv('../results/sub_table.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing of Surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_10_10_RPP_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_11_21_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_9_26_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_9_26_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_9_26_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_9_26_ambiparticipant_table.csv\n",
      "failed\n",
      "../../batchlogs/hit_batch_2016_9_26_ambip"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 10027 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_participants = pd.read_csv('../results/sub_table.csv')\n",
    "files = glob.glob('../../batchlogs/*')\n",
    "for f in files:\n",
    "\n",
    "    d =pd.read_csv(f) # get table\n",
    "\n",
    "    # loop through this table\n",
    "    for index, row in d.iterrows():\n",
    "        \n",
    "        MID = str(row.MID)\n",
    "        try:\n",
    "            #print(row)\n",
    "            progress_times = row.progress_times.split(';') # find corresponding start and end time\n",
    "            \n",
    "            \n",
    "            # Questionnaires\n",
    "            for name in ['STAI_State','STAI_Trait','BDI','MASQ','EPQ','CESD','PSWQ','ASIR','IUS']:\n",
    "                matching = [s for s in progress_times if name+\" start\" in s]\n",
    "                if matching is not None:\n",
    "                    start = matching[0].split(':')[1]\n",
    "                    matching = [s for s in progress_times if name+\" end\" in s]\n",
    "                    end = matching[0].split(':')[1]\n",
    "                    duration = float(end)-float(start)\n",
    "                    data_participants.loc[(data_participants.MID==MID) \n",
    "                                          & (data_participants.date==str(get_date_from_filename(f))),'duration_'+name]=duration\n",
    "                    data_participants.loc[(data_participants.MID==MID) \n",
    "                                          & (data_participants.date==str(get_date_from_filename(f))),'starttime_'+name]=float(start)\n",
    "                    data_participants.loc[(data_participants.MID==MID) \n",
    "                                          & (data_participants.date==str(get_date_from_filename(f))),'endtime_'+name]=float(end)\n",
    "                else:\n",
    "                    data_participants.loc[(data_participants.MID==MID)\n",
    "                                          & (data_participants.date==str(get_date_from_filename(f))),'duration_'+name]=np.nan\n",
    "                    data_participants.loc[(data_participants.MID==MID)\n",
    "                                          & (data_participants.date==str(get_date_from_filename(f))),'starttime_'+name]=np.nan\n",
    "                    data_participants.loc[(data_participants.MID==MID) \n",
    "                                          & (data_participants.date==str(get_date_from_filename(f))),'endtime_'+name]=np.nan\n",
    "\n",
    "        except: \n",
    "            print('failed')\n",
    "            print(f)\n",
    "            #print(MID)\n",
    "\n",
    "data_participants.to_csv('../results/sub_table.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing of Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_participants = pd.read_csv('../results/sub_table.csv')\n",
    "for f in files:\n",
    "\n",
    "    d =pd.read_csv(f) # get table\n",
    "\n",
    "    # loop through this table\n",
    "    for index, row in d.iterrows():\n",
    "        \n",
    "        MID = str(row.MID)\n",
    "        try:\n",
    "            #print(row)\n",
    "            progress_times = row.progress_times2.split(';') # find corresponding start and end time\n",
    "            \n",
    "            \n",
    "            # Questionnaires\n",
    "            for name in ['ambi combined']:\n",
    "                matching = [s for s in progress_times if name+\" start\" in s]\n",
    "                if matching is not None:\n",
    "                    #start = datetime.datetime.strptime(matching[0].split(' ')[-1].split('.')[0],'%H:%M:%S')\n",
    "                    start = datetime.datetime.strptime(matching[0].split('start')[-1],':%Y-%m-%d %H:%M:%S.%f')\n",
    "                    start_abs_seconds = (start-datetime.datetime(1970,1,1)).total_seconds()\n",
    "\n",
    "                    matching = [s for s in progress_times if name+\" end\" in s]\n",
    "                    #end = datetime.datetime.strptime(matching[0].split(' ')[-1].split('.')[0],'%H:%M:%S')\n",
    "                    # puts date in\n",
    "                    end = datetime.datetime.strptime(matching[0].split('end')[-1],':%Y-%m-%d %H:%M:%S.%f')\n",
    "                    end_abs_seconds = (end-datetime.datetime(1970,1,1)).total_seconds()\n",
    "                    \n",
    "                    duration = end-start\n",
    "                    #print(duration.seconds)\n",
    "                    data_participants.loc[(data_participants.MID==MID) \n",
    "                                          & (data_participants.date==str(get_date_from_filename(f))),'duration_'+name]=float(duration.seconds)\n",
    "                    data_participants.loc[(data_participants.MID==MID) \n",
    "                                          & (data_participants.date==str(get_date_from_filename(f))),'starttime_'+name]=float(start_abs_seconds)\n",
    "                    data_participants.loc[(data_participants.MID==MID) \n",
    "                                          & (data_participants.date==str(get_date_from_filename(f))),'endtime_'+name]=float(end_abs_seconds)\n",
    "                else:\n",
    "                    data_participants.loc[(data_participants.MID==MID)\n",
    "                                          & (data_participants.date==str(get_date_from_filename(f))),'duration_'+name]=np.nan\n",
    "                    data_participants.loc[(data_participants.MID==MID)\n",
    "                                          & (data_participants.date==str(get_date_from_filename(f))),'starttime_'+name]=np.nan\n",
    "                    data_participants.loc[(data_participants.MID==MID) \n",
    "                                          & (data_participants.date==str(get_date_from_filename(f))),'endtime_'+name]=np.nan\n",
    "\n",
    "        except: \n",
    "            x=1\n",
    "\n",
    "data_participants.to_csv('../results/sub_table.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AID                        3D8YOU6S9FPNHDBKQJOZO3ZU9436U5\n",
       "ASIR                                                  NaN\n",
       "ASIR_had_to_drop_rows                                 NaN\n",
       "ASIR_unique_responses                                 NaN\n",
       "BDI                                                    31\n",
       "BDI_had_to_drop_rows                                    0\n",
       "BDI_unique_responses                                    4\n",
       "CESD                                                   26\n",
       "CESD_had_to_drop_rows                                   1\n",
       "CESD_unique_responses                                   3\n",
       "EPQ                                                    22\n",
       "EPQ_had_to_drop_rows                                    0\n",
       "EPQ_unique_responses                                    2\n",
       "IUS                                                    93\n",
       "IUS1                                                   44\n",
       "IUS2                                                   49\n",
       "IUS_had_to_drop_rows                                    0\n",
       "IUS_unique_responses                                    5\n",
       "MASQ.AA                                                20\n",
       "MASQ.AD                                                89\n",
       "MASQ.AS                                                17\n",
       "MASQ.DS                                                31\n",
       "MASQ.MS                                                38\n",
       "MASQ_had_to_drop_rows                                   0\n",
       "MASQ_unique_responses                                   4\n",
       "MID                                        A1GHQFNWXYP1RS\n",
       "PSWQ                                                   81\n",
       "PSWQ_had_to_drop_rows                                   0\n",
       "PSWQ_unique_responses                                   3\n",
       "STAI_State                                             57\n",
       "                                        ...              \n",
       "duration_STAI_State                                    74\n",
       "starttime_STAI_State                          1.49755e+09\n",
       "endtime_STAI_State                            1.49755e+09\n",
       "duration_STAI_Trait                                    53\n",
       "starttime_STAI_Trait                          1.49755e+09\n",
       "endtime_STAI_Trait                            1.49755e+09\n",
       "duration_BDI                                          116\n",
       "starttime_BDI                                 1.49755e+09\n",
       "endtime_BDI                                   1.49755e+09\n",
       "duration_MASQ                                         178\n",
       "starttime_MASQ                                1.49755e+09\n",
       "endtime_MASQ                                  1.49756e+09\n",
       "duration_EPQ                                          187\n",
       "starttime_EPQ                                 1.49756e+09\n",
       "endtime_EPQ                                   1.49756e+09\n",
       "duration_CESD                                          47\n",
       "starttime_CESD                                1.49756e+09\n",
       "endtime_CESD                                  1.49756e+09\n",
       "duration_PSWQ                                          47\n",
       "starttime_PSWQ                                1.49756e+09\n",
       "endtime_PSWQ                                  1.49756e+09\n",
       "duration_ASIR                                         NaN\n",
       "starttime_ASIR                                        NaN\n",
       "endtime_ASIR                                          NaN\n",
       "duration_IUS                                          NaN\n",
       "starttime_IUS                                         NaN\n",
       "endtime_IUS                                           NaN\n",
       "duration_ambi combined                               3077\n",
       "starttime_ambi combined                       1.49756e+09\n",
       "endtime_ambi combined                         1.49756e+09\n",
       "Name: 192, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_participants.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding parameters from logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_participants = pd.read_csv('../results/sub_table.csv')\n",
    "\n",
    "results_folder = '../results/log_reg_model_results/individual_subjects/'\n",
    "resultnames = ['bic','aic','pseudoR2','pred_acc']\n",
    "\n",
    "whichones = ['0','1','2']\n",
    "whichones = ['3','4']\n",
    "#whichones = ['5','6','7','8','9']\n",
    "whichones = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25']\n",
    "# whichones = ['10','11','13','14']\n",
    "\n",
    "# whichones = ['0','1','8']\n",
    "# whichones = ['-1']\n",
    "# whichones = ['2','3']\n",
    "\n",
    "#whichones = ['-1','2','3','4','5']\n",
    "whichones=['4','5','6']\n",
    "whichones=['18']\n",
    "for paramnum in whichones:\n",
    "    try:\n",
    "        \n",
    "        for split in ['ambig_gain','ambig_loss']:\n",
    "        #for split in ['unambig_gain','unambig_loss']:\n",
    "            modelname = 'model_split_'+split+'_'.join(param_sets_split[paramnum])\n",
    "            files = glob.glob(results_folder+'*'+modelname+'.p')\n",
    "            for filee in files:\n",
    "                model_results = pickle.load(open(filee,'rb'))\n",
    "                MID = str(model_results['MID'])\n",
    "                task = get_gain_loss_from_filename(filee)\n",
    "                params = model_results['params']\n",
    "\n",
    "                for result in resultnames:\n",
    "                    data_participants.loc[(data_participants.MID==MID) & \n",
    "                                      (data_participants.date==str(get_date_from_filename(filee))),\n",
    "                                       modelname+'_'+result+'_'+task]=model_results[result]\n",
    "                for param in params.index:\n",
    "                    data_participants.loc[(data_participants.MID==MID) & \n",
    "                                      (data_participants.date==str(get_date_from_filename(filee))),\n",
    "                                       modelname+'_'+param+'_'+task]=params[param]\n",
    "    except:\n",
    "        print('didnt add:'+paramnum)\n",
    "        \n",
    "data_participants.to_csv('../results/sub_table.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mscl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_participants = pd.read_csv('../results/sub_table.csv')\n",
    "data_participants.MID = data_participants.MID.astype('str')\n",
    "data_participants.to_csv('../results/sub_table.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data (Examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data (Specify Group of Subjects )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AID</th>\n",
       "      <th>ASIR</th>\n",
       "      <th>ASIR_had_to_drop_rows</th>\n",
       "      <th>ASIR_unique_responses</th>\n",
       "      <th>BDI</th>\n",
       "      <th>BDI_had_to_drop_rows</th>\n",
       "      <th>BDI_unique_responses</th>\n",
       "      <th>CESD</th>\n",
       "      <th>CESD_had_to_drop_rows</th>\n",
       "      <th>CESD_unique_responses</th>\n",
       "      <th>...</th>\n",
       "      <th>model_split_ambig_lossmag_diff_prob_diff_sqrt_prop_revealed_prob_total_inter_prob_diff_sqrt_prop_revealed_inter_prob_total_sqrt_prop_revealed_inter_prob_total_prob_diff_sqrt_prop_revealed_inter_prob_total_prob_diff_sqrt_prop_revealed_combined</th>\n",
       "      <th>flexible_prior0_bic_combined</th>\n",
       "      <th>flexible_prior0_aic_combined</th>\n",
       "      <th>flexible_prior0_pseudoR2_combined</th>\n",
       "      <th>flexible_prior0_pred_acc_combined</th>\n",
       "      <th>flexible_prior0_B0_combined</th>\n",
       "      <th>flexible_prior0_B1_combined</th>\n",
       "      <th>flexible_prior0_B2_combined</th>\n",
       "      <th>flexible_prior0_alpha_combined</th>\n",
       "      <th>flexible_prior0_beta_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33LK57MYLUA9QA3R3JQA60A1P97ZST</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.898181</td>\n",
       "      <td>67.114637</td>\n",
       "      <td>0.439177</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>-0.651968</td>\n",
       "      <td>-2.589137</td>\n",
       "      <td>0.068135</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3QRYMNZ7FZMGOL2NPVK6LIZEHEGNTS</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.159974</td>\n",
       "      <td>5.436703</td>\n",
       "      <td>16.828380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34YB12FSQZT61YVHTU6Z9KVPMT9MGR</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3DUZQ9U6SNTSHQYH2M17LUX51XBVSX</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.894537</td>\n",
       "      <td>96.110993</td>\n",
       "      <td>0.189753</td>\n",
       "      <td>0.705128</td>\n",
       "      <td>-0.024690</td>\n",
       "      <td>5.437591</td>\n",
       "      <td>0.011709</td>\n",
       "      <td>4.593528</td>\n",
       "      <td>5.931948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30LB5CDZNDF9P1JFUH7QWU4IUHT0ZC</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>-0.534918</td>\n",
       "      <td>1.909465</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.628110</td>\n",
       "      <td>12.987043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 664 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              AID  ASIR  ASIR_had_to_drop_rows  \\\n",
       "0  33LK57MYLUA9QA3R3JQA60A1P97ZST    28                      0   \n",
       "1  3QRYMNZ7FZMGOL2NPVK6LIZEHEGNTS    58                      0   \n",
       "2  34YB12FSQZT61YVHTU6Z9KVPMT9MGR    25                      0   \n",
       "3  3DUZQ9U6SNTSHQYH2M17LUX51XBVSX    10                      0   \n",
       "4  30LB5CDZNDF9P1JFUH7QWU4IUHT0ZC    30                      0   \n",
       "\n",
       "   ASIR_unique_responses  BDI  BDI_had_to_drop_rows  BDI_unique_responses  \\\n",
       "0                      5    1                     0                     2   \n",
       "1                      5   11                     0                     3   \n",
       "2                      4    7                     0                     3   \n",
       "3                      3    3                     0                     2   \n",
       "4                      4   15                     0                     2   \n",
       "\n",
       "   CESD  CESD_had_to_drop_rows  CESD_unique_responses  \\\n",
       "0     5                      0                      4   \n",
       "1    19                      0                      3   \n",
       "2     4                      0                      4   \n",
       "3     6                      0                      4   \n",
       "4    22                      0                      4   \n",
       "\n",
       "               ...                \\\n",
       "0              ...                 \n",
       "1              ...                 \n",
       "2              ...                 \n",
       "3              ...                 \n",
       "4              ...                 \n",
       "\n",
       "   model_split_ambig_lossmag_diff_prob_diff_sqrt_prop_revealed_prob_total_inter_prob_diff_sqrt_prop_revealed_inter_prob_total_sqrt_prop_revealed_inter_prob_total_prob_diff_sqrt_prop_revealed_inter_prob_total_prob_diff_sqrt_prop_revealed_combined  \\\n",
       "0                                                NaN                                                                                                                                                                                                    \n",
       "1                                                NaN                                                                                                                                                                                                    \n",
       "2                                                NaN                                                                                                                                                                                                    \n",
       "3                                                NaN                                                                                                                                                                                                    \n",
       "4                                                NaN                                                                                                                                                                                                    \n",
       "\n",
       "   flexible_prior0_bic_combined  flexible_prior0_aic_combined  \\\n",
       "0                     78.898181                     67.114637   \n",
       "1                           NaN                           NaN   \n",
       "2                           NaN                           NaN   \n",
       "3                    107.894537                     96.110993   \n",
       "4                           NaN                           NaN   \n",
       "\n",
       "   flexible_prior0_pseudoR2_combined  flexible_prior0_pred_acc_combined  \\\n",
       "0                           0.439177                           0.897436   \n",
       "1                                NaN                           0.564103   \n",
       "2                                NaN                           0.000000   \n",
       "3                           0.189753                           0.705128   \n",
       "4                                NaN                           0.756410   \n",
       "\n",
       "   flexible_prior0_B0_combined  flexible_prior0_B1_combined  \\\n",
       "0                    -0.651968                    -2.589137   \n",
       "1                   -10.000000                    10.000000   \n",
       "2                          NaN                          NaN   \n",
       "3                    -0.024690                     5.437591   \n",
       "4                    -0.534918                     1.909465   \n",
       "\n",
       "   flexible_prior0_B2_combined  flexible_prior0_alpha_combined  \\\n",
       "0                     0.068135                       20.000000   \n",
       "1                     7.159974                        5.436703   \n",
       "2                          NaN                             NaN   \n",
       "3                     0.011709                        4.593528   \n",
       "4                    10.000000                       11.628110   \n",
       "\n",
       "   flexible_prior0_beta_combined  \n",
       "0                      20.000000  \n",
       "1                      16.828380  \n",
       "2                            NaN  \n",
       "3                       5.931948  \n",
       "4                      12.987043  \n",
       "\n",
       "[5 rows x 664 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_participants = pd.read_csv('../results/sub_table.csv')\n",
    "data_participants = data_participants.loc[\n",
    "    ~np.isnan(data_participants.num_no_resp_combined)&\n",
    "    ((data_participants.date=='2017-04-17')|(data_participants.date=='2017-03-06'))|(data_participants.date=='2017-06-14')]\n",
    "datasetfolder='datasetb'\n",
    "data_participants.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AID</th>\n",
       "      <th>ASIR</th>\n",
       "      <th>ASIR_had_to_drop_rows</th>\n",
       "      <th>ASIR_unique_responses</th>\n",
       "      <th>BDI</th>\n",
       "      <th>BDI_had_to_drop_rows</th>\n",
       "      <th>BDI_unique_responses</th>\n",
       "      <th>CESD</th>\n",
       "      <th>CESD_had_to_drop_rows</th>\n",
       "      <th>CESD_unique_responses</th>\n",
       "      <th>...</th>\n",
       "      <th>model_split_ambig_lossmag_diff_prob_diff_sqrt_prop_revealed_prob_total_inter_prob_diff_sqrt_prop_revealed_inter_prob_total_sqrt_prop_revealed_inter_prob_total_prob_diff_sqrt_prop_revealed_inter_prob_total_prob_diff_sqrt_prop_revealed_combined</th>\n",
       "      <th>flexible_prior0_bic_combined</th>\n",
       "      <th>flexible_prior0_aic_combined</th>\n",
       "      <th>flexible_prior0_pseudoR2_combined</th>\n",
       "      <th>flexible_prior0_pred_acc_combined</th>\n",
       "      <th>flexible_prior0_B0_combined</th>\n",
       "      <th>flexible_prior0_B1_combined</th>\n",
       "      <th>flexible_prior0_B2_combined</th>\n",
       "      <th>flexible_prior0_alpha_combined</th>\n",
       "      <th>flexible_prior0_beta_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>3D8YOU6S9FPNHDBKQJOZO3ZU9436U5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 664 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                AID  ASIR  ASIR_had_to_drop_rows  \\\n",
       "192  3D8YOU6S9FPNHDBKQJOZO3ZU9436U5   NaN                    NaN   \n",
       "\n",
       "     ASIR_unique_responses  BDI  BDI_had_to_drop_rows  BDI_unique_responses  \\\n",
       "192                    NaN   31                     0                     4   \n",
       "\n",
       "     CESD  CESD_had_to_drop_rows  CESD_unique_responses  \\\n",
       "192    26                      1                      3   \n",
       "\n",
       "                 ...                \\\n",
       "192              ...                 \n",
       "\n",
       "     model_split_ambig_lossmag_diff_prob_diff_sqrt_prop_revealed_prob_total_inter_prob_diff_sqrt_prop_revealed_inter_prob_total_sqrt_prop_revealed_inter_prob_total_prob_diff_sqrt_prop_revealed_inter_prob_total_prob_diff_sqrt_prop_revealed_combined  \\\n",
       "192                                                NaN                                                                                                                                                                                                    \n",
       "\n",
       "     flexible_prior0_bic_combined  flexible_prior0_aic_combined  \\\n",
       "192                           NaN                           NaN   \n",
       "\n",
       "     flexible_prior0_pseudoR2_combined  flexible_prior0_pred_acc_combined  \\\n",
       "192                                NaN                                NaN   \n",
       "\n",
       "     flexible_prior0_B0_combined  flexible_prior0_B1_combined  \\\n",
       "192                          NaN                          NaN   \n",
       "\n",
       "     flexible_prior0_B2_combined  flexible_prior0_alpha_combined  \\\n",
       "192                          NaN                             NaN   \n",
       "\n",
       "     flexible_prior0_beta_combined  \n",
       "192                            NaN  \n",
       "\n",
       "[1 rows x 664 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_participants.loc[data_participants.MID=='A1GHQFNWXYP1RS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2017-04-17', '2017-06-14'], dtype=object)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_participants.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data_participants['model_split_amb_unamb_gain_loss_aic_combined']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load single model data w parameter and beta as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelname = 'model_singRL_mag_diff_rl_prob_diff_rl_ambig_present_sqrt_prop_revealed'\n",
    "modelname = 'model_split_amb_unamb_gain_loss'\n",
    "df=get_params_df(modelname,'combined',data_participants,combined=True)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "343px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "932px",
    "left": "0px",
    "right": "1422.67px",
    "top": "107px",
    "width": "440px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
